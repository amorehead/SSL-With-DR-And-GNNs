% Created 2021-11-02 Tue 20:51
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Alex Morehead \& Watchanan Chantapakul}
\date{\today}
\title{Semi-Supervised Graph Learning Meets Dimensionality Reduction\\\medskip
\large Final Project for Unsupervised Learning in Fall 2021}
\hypersetup{
 pdfauthor={Alex Morehead \& Watchanan Chantapakul},
 pdftitle={Semi-Supervised Graph Learning Meets Dimensionality Reduction},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.5)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{Project Proposal}
\label{sec:orgf6f8df7}
\subsection{Abstract}
\label{sec:org0b0f742}
Semi-supervised learning (SSL) has recently received increased attention by
machine learning researchers \cite{DBLP:journals/corr/KipfW16}. By enabling
effective propagation of known labels in graph-based deep learning (GDL)
algorithms, SSL is poised to become an increasingly-used technique in GDL in the
coming years. However, there are currently few explorations in the graph-based
SSL literature on exploiting classical dimensionality reduction techniques for
improved label propagation \cite{YU20121119}, \cite{hong2019learning}. In this work,
we propose to investigate the use of dimensionality reduction techniques such as
PCA, t-SNE, and UMAP to see their effect on the performance of graph neural
networks (GNNs) designed for semi-supervised propagation of node labels. Our
study will make use of benchmark semi-supervised GDL datasets such as the Cora
and Citeseer datasets to allow meaningful comparisons of the representations
learned by each algorithm when paired with a dimensionality reduction technique.
Our node classification results will be reported in terms of cross entropy loss,
precision, recall, and F1 score.
\subsection{Responsibilities}
\label{sec:orgf7e3d93}
\begin{enumerate}
\item Alex Morehead - Responsible for Graph Deep Learning Tasks
\item Watchanan Chantapakul - Responsible for Dimensionality Reduction Tasks
\end{enumerate}
\subsection{Timeline}
\label{sec:org3ae2b44}
\begin{itemize}
\item 11/11/2021: Have baseline graph deep learning environment for training models completed
\item 11/16/2021: Have dimensionality reduction algorithms selected
\item 11/18/2021: Have rough first versions of each dimensionality reduction algorithm implemented
\item 11/23/2021: Have underway integration of dimensionality reduction algorithms into our deep learning environment
\item 11/25/2021: Have rough first version of deep learning models training with \(a priori\) dimensionality reduction
\item 11/30/2021: Have underway refinement of deep learning models and their results
\item 12/02/2021: Have analysis of model results and presentation preparation underway
\item 12/07/2021: Present study's results
\item 12/09/2021: Have composition of final project report underway
\item 12/14/2021: Have first few drafts of final project report completed
\item 12/16/2021: Submit final project report
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{../../../../../../../Bibliographies/mindmeld}
\end{document}
